{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<p><img src=\"https://mcd.unison.mx/wp-content/themes/awaken/img/logo_mcd.png\" width=\"150\">\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "# Curso *Ingeniería de Características*\n",
    "\n",
    "### Descargando datos\n",
    "\n",
    "\n",
    "<p> Julio Waissman Vilanova </p>\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mcd-unison/ing-caract/blob/main/ejemplos/integracion/python/descarga_datos.ipynb\"><img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Ejecuta en Google Colab</a>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Descargando datos a la fuerza bruta\n",
    "\n",
    "Vamos a ver primero como ir descargando datos y luego como lidiar con diferentes formatos. Es muy importante que, si los datos los vamos a cargar por única vez, descargar el conjunto de datos, tal como se encuentran, esto es `raw data`.\n",
    "\n",
    "Vamos primero cargando las bibliotecas necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os  # Para manejo de archivos y directorios\n",
    "import urllib.request # Una forma estandard de descargar datos\n",
    "# import requests # Otra forma no de las librerías de uso comun\n",
    "\n",
    "import datetime # Fecha de descarga\n",
    "import pandas as pd # Solo para ver el archivo descargado\n",
    "import zipfile # Descompresión de archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante saber en donde nos encontramos y crear los subdirectorios necesarios para guardar los datos de manera ordenada. Tambien es importante evitar cargar datos que ya han sido descargados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brayan/Downloads/descargando_datos\n"
     ]
    }
   ],
   "source": [
    "# pwd\n",
    "print(os.getcwd())\n",
    "\n",
    "#  Estos son los datos que vamos a descargar y donde vamos a guardarlos\n",
    "desaparecidos_RNPDNO_url = \"http://www.datamx.io/dataset/fdd2ca20-ee70-4a31-9bdf-823f3c1307a2/resource/d352810c-a22e-4d72-bb3b-33c742c799dd/download/desaparecidos3ago.zip\"\n",
    "desaparecidos_RNPDNO_archivo = \"desaparecidosRNPDNO.zip\"\n",
    "desaparecidos_corte_nacional_url = \"http://www.datamx.io/dataset/fdd2ca20-ee70-4a31-9bdf-823f3c1307a2/resource/4865e244-cf59-4d39-b863-96ed7f45cc70/download/nacional.json\"\n",
    "desaparecidos_corte_nacional_archivo = \"desaparecidos_nacional.json\"\n",
    "subdir = \"./data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(desaparecidos_RNPDNO_archivo):\n",
    "    if not os.path.exists(subdir):\n",
    "        os.makedirs(subdir)\n",
    "    urllib.request.urlretrieve(desaparecidos_RNPDNO_url, subdir + desaparecidos_RNPDNO_archivo)  \n",
    "    with zipfile.ZipFile(subdir + desaparecidos_RNPDNO_archivo, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(subdir)\n",
    "    \n",
    "    urllib.request.urlretrieve(desaparecidos_corte_nacional_url, subdir + desaparecidos_corte_nacional_archivo)  \n",
    "\n",
    "    with open(subdir + \"info.txt\", 'w') as f:\n",
    "        f.write(\"Archivos sobre personas desaparecidas\\n\")\n",
    "        info = \"\"\"\n",
    "        Datos de desaparecidos, corte nacional y desagregación a nivel estatal, \n",
    "        por edad, por sexo, por nacionalidad, por año de desaparición y por mes\n",
    "        de desaparición para los últimos 12 meses.\n",
    "\n",
    "        Los datos se obtuvieron del RNPDNO con fecha de 03 de agosto de 2021\n",
    "        (la base de datos no se ha actualizado últimamente) \n",
    "\n",
    "        \"\"\" \n",
    "        f.write(info + '\\n')\n",
    "        f.write(\"Descargado el \" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\")\n",
    "        f.write(\"Desde: \" + desaparecidos_RNPDNO_url + \"\\n\")\n",
    "        f.write(\"Nombre: \" + desaparecidos_RNPDNO_archivo + \"\\n\")\n",
    "        f.write(\"Agregados nacionales descargados desde: \" + desaparecidos_corte_nacional_url + \"\\n\")\n",
    "        f.write(\"Nombre: \" + desaparecidos_corte_nacional_archivo + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Archivos en formato `json`\n",
    "\n",
    "Los archivos en formato json son posiblemente los más utilizados actualmente para transferir información por internet, ya que se usa en prácticamente todas las REST API. Como acabamos de ver es normal tener que enfrentarse con archivos `json` pésimamente o nada documentados, por lo que es necesario saber como tratarlos. \n",
    "\n",
    "Vamos a ver como se hace eso utilizando la bibloteca de `json`y la de `pandas`. Para `pandas`les recomiendo, si no lo conocen, de darle una vuelta a [la documentación y los tutoriales](https://pandas.pydata.org/docs/) que está muy bien hecha. O a el [curso básico de Kaggle](https://www.kaggle.com/learn/pandas).\n",
    "\n",
    "Sobre `json`, posiblemente [la página con la especificación](https://www.json.org/json-en.html) sea más que suficiente. \n",
    "\n",
    "Vamos a hacer un ejemplito sencillo y carismático revisando los repositorios de [github](https://github.com) y les voy a dejar que exploren los `json` de los archivos de personas desaparecidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Esto es como una segunda piel\n",
    "import json # Una forma estandar de leer archivos json \n",
    "\n",
    "archivo_url = \"https://api.github.com/users/google/repos\"\n",
    "archivo_nombre = \"repos-google.json\"\n",
    "subdir = \"./data/\"\n",
    "\n",
    "if not os.path.exists(subdir + archivo_nombre):\n",
    "    if not os.path.exists(subdir):\n",
    "        os.makedirs(subdir)\n",
    "    urllib.request.urlretrieve(archivo_url, subdir + archivo_nombre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos primero a ver como le hacemos con `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>private</th>\n",
       "      <th>owner</th>\n",
       "      <th>html_url</th>\n",
       "      <th>description</th>\n",
       "      <th>fork</th>\n",
       "      <th>url</th>\n",
       "      <th>...</th>\n",
       "      <th>license</th>\n",
       "      <th>allow_forking</th>\n",
       "      <th>is_template</th>\n",
       "      <th>web_commit_signoff_required</th>\n",
       "      <th>topics</th>\n",
       "      <th>visibility</th>\n",
       "      <th>forks</th>\n",
       "      <th>open_issues</th>\n",
       "      <th>watchers</th>\n",
       "      <th>default_branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>460600860</td>\n",
       "      <td>R_kgDOG3Q2HA</td>\n",
       "      <td>.allstar</td>\n",
       "      <td>google/.allstar</td>\n",
       "      <td>False</td>\n",
       "      <td>{'login': 'google', 'id': 1342004, 'node_id': ...</td>\n",
       "      <td>https://github.com/google/.allstar</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/google/.allstar</td>\n",
       "      <td>...</td>\n",
       "      <td>{'key': 'apache-2.0', 'name': 'Apache License ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>public</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170908616</td>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNzA5MDg2MTY=</td>\n",
       "      <td>.github</td>\n",
       "      <td>google/.github</td>\n",
       "      <td>False</td>\n",
       "      <td>{'login': 'google', 'id': 1342004, 'node_id': ...</td>\n",
       "      <td>https://github.com/google/.github</td>\n",
       "      <td>default configuration for @google repos</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/google/.github</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>public</td>\n",
       "      <td>353</td>\n",
       "      <td>29</td>\n",
       "      <td>109</td>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143044068</td>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNDMwNDQwNjg=</td>\n",
       "      <td>0x0g-2018-badge</td>\n",
       "      <td>google/0x0g-2018-badge</td>\n",
       "      <td>False</td>\n",
       "      <td>{'login': 'google', 'id': 1342004, 'node_id': ...</td>\n",
       "      <td>https://github.com/google/0x0g-2018-badge</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/google/0x0g-2018-...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'key': 'apache-2.0', 'name': 'Apache License ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>public</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>424674738</td>\n",
       "      <td>R_kgDOGVAFsg</td>\n",
       "      <td>aarch64-esr-decoder</td>\n",
       "      <td>google/aarch64-esr-decoder</td>\n",
       "      <td>False</td>\n",
       "      <td>{'login': 'google', 'id': 1342004, 'node_id': ...</td>\n",
       "      <td>https://github.com/google/aarch64-esr-decoder</td>\n",
       "      <td>A utility for decoding aarch64 ESR register va...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/google/aarch64-es...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'key': 'apache-2.0', 'name': 'Apache License ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[aarch64]</td>\n",
       "      <td>public</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487987687</td>\n",
       "      <td>R_kgDOHRYZ5w</td>\n",
       "      <td>aarch64-paging</td>\n",
       "      <td>google/aarch64-paging</td>\n",
       "      <td>False</td>\n",
       "      <td>{'login': 'google', 'id': 1342004, 'node_id': ...</td>\n",
       "      <td>https://github.com/google/aarch64-paging</td>\n",
       "      <td>A Rust library to manipulate AArch64 VMSA EL1 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/google/aarch64-pa...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'key': 'other', 'name': 'Other', 'spdx_id': '...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[aarch64, pagetable, rust, rust-crate, vmsa]</td>\n",
       "      <td>public</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                           node_id                 name  \\\n",
       "0  460600860                      R_kgDOG3Q2HA             .allstar   \n",
       "1  170908616  MDEwOlJlcG9zaXRvcnkxNzA5MDg2MTY=              .github   \n",
       "2  143044068  MDEwOlJlcG9zaXRvcnkxNDMwNDQwNjg=      0x0g-2018-badge   \n",
       "3  424674738                      R_kgDOGVAFsg  aarch64-esr-decoder   \n",
       "4  487987687                      R_kgDOHRYZ5w       aarch64-paging   \n",
       "\n",
       "                    full_name  private  \\\n",
       "0             google/.allstar    False   \n",
       "1              google/.github    False   \n",
       "2      google/0x0g-2018-badge    False   \n",
       "3  google/aarch64-esr-decoder    False   \n",
       "4       google/aarch64-paging    False   \n",
       "\n",
       "                                               owner  \\\n",
       "0  {'login': 'google', 'id': 1342004, 'node_id': ...   \n",
       "1  {'login': 'google', 'id': 1342004, 'node_id': ...   \n",
       "2  {'login': 'google', 'id': 1342004, 'node_id': ...   \n",
       "3  {'login': 'google', 'id': 1342004, 'node_id': ...   \n",
       "4  {'login': 'google', 'id': 1342004, 'node_id': ...   \n",
       "\n",
       "                                        html_url  \\\n",
       "0             https://github.com/google/.allstar   \n",
       "1              https://github.com/google/.github   \n",
       "2      https://github.com/google/0x0g-2018-badge   \n",
       "3  https://github.com/google/aarch64-esr-decoder   \n",
       "4       https://github.com/google/aarch64-paging   \n",
       "\n",
       "                                         description   fork  \\\n",
       "0                                               None  False   \n",
       "1            default configuration for @google repos  False   \n",
       "2                                               None  False   \n",
       "3  A utility for decoding aarch64 ESR register va...  False   \n",
       "4  A Rust library to manipulate AArch64 VMSA EL1 ...  False   \n",
       "\n",
       "                                                 url  ...  \\\n",
       "0       https://api.github.com/repos/google/.allstar  ...   \n",
       "1        https://api.github.com/repos/google/.github  ...   \n",
       "2  https://api.github.com/repos/google/0x0g-2018-...  ...   \n",
       "3  https://api.github.com/repos/google/aarch64-es...  ...   \n",
       "4  https://api.github.com/repos/google/aarch64-pa...  ...   \n",
       "\n",
       "                                             license allow_forking  \\\n",
       "0  {'key': 'apache-2.0', 'name': 'Apache License ...          True   \n",
       "1                                               None          True   \n",
       "2  {'key': 'apache-2.0', 'name': 'Apache License ...          True   \n",
       "3  {'key': 'apache-2.0', 'name': 'Apache License ...          True   \n",
       "4  {'key': 'other', 'name': 'Other', 'spdx_id': '...          True   \n",
       "\n",
       "  is_template web_commit_signoff_required  \\\n",
       "0       False                       False   \n",
       "1       False                       False   \n",
       "2       False                       False   \n",
       "3       False                       False   \n",
       "4       False                       False   \n",
       "\n",
       "                                         topics visibility forks open_issues  \\\n",
       "0                                            []     public     1           0   \n",
       "1                                            []     public   353          29   \n",
       "2                                            []     public     4           0   \n",
       "3                                     [aarch64]     public    19           1   \n",
       "4  [aarch64, pagetable, rust, rust-crate, vmsa]     public    11           5   \n",
       "\n",
       "  watchers default_branch  \n",
       "0        8           main  \n",
       "1      109         master  \n",
       "2       19         master  \n",
       "3       99           main  \n",
       "4       39           main  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repos = pd.read_json(subdir + archivo_nombre)\n",
    "\n",
    "df_repos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y si nos fijamos `owner` es un diccionario, por lo que es necesario obtener su información en forma `tidy` (por cada columna un artibuto y por cada renglon una instancia), lo que haremos de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>private</th>\n",
       "      <th>html_url</th>\n",
       "      <th>description</th>\n",
       "      <th>fork</th>\n",
       "      <th>url</th>\n",
       "      <th>forks_url</th>\n",
       "      <th>...</th>\n",
       "      <th>owner.received_events_url</th>\n",
       "      <th>owner.type</th>\n",
       "      <th>owner.user_view_type</th>\n",
       "      <th>owner.site_admin</th>\n",
       "      <th>license.key</th>\n",
       "      <th>license.name</th>\n",
       "      <th>license.spdx_id</th>\n",
       "      <th>license.url</th>\n",
       "      <th>license.node_id</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>460600860</td>\n",
       "      <td>R_kgDOG3Q2HA</td>\n",
       "      <td>.allstar</td>\n",
       "      <td>google/.allstar</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/google/.allstar</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/google/.allstar</td>\n",
       "      <td>https://api.github.com/repos/google/.allstar/f...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/users/google/received_e...</td>\n",
       "      <td>Organization</td>\n",
       "      <td>public</td>\n",
       "      <td>False</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>Apache License 2.0</td>\n",
       "      <td>Apache-2.0</td>\n",
       "      <td>https://api.github.com/licenses/apache-2.0</td>\n",
       "      <td>MDc6TGljZW5zZTI=</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170908616</td>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNzA5MDg2MTY=</td>\n",
       "      <td>.github</td>\n",
       "      <td>google/.github</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/google/.github</td>\n",
       "      <td>default configuration for @google repos</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/google/.github</td>\n",
       "      <td>https://api.github.com/repos/google/.github/forks</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/users/google/received_e...</td>\n",
       "      <td>Organization</td>\n",
       "      <td>public</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>143044068</td>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNDMwNDQwNjg=</td>\n",
       "      <td>0x0g-2018-badge</td>\n",
       "      <td>google/0x0g-2018-badge</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/google/0x0g-2018-badge</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/google/0x0g-2018-...</td>\n",
       "      <td>https://api.github.com/repos/google/0x0g-2018-...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/users/google/received_e...</td>\n",
       "      <td>Organization</td>\n",
       "      <td>public</td>\n",
       "      <td>False</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>Apache License 2.0</td>\n",
       "      <td>Apache-2.0</td>\n",
       "      <td>https://api.github.com/licenses/apache-2.0</td>\n",
       "      <td>MDc6TGljZW5zZTI=</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>424674738</td>\n",
       "      <td>R_kgDOGVAFsg</td>\n",
       "      <td>aarch64-esr-decoder</td>\n",
       "      <td>google/aarch64-esr-decoder</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/google/aarch64-esr-decoder</td>\n",
       "      <td>A utility for decoding aarch64 ESR register va...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/google/aarch64-es...</td>\n",
       "      <td>https://api.github.com/repos/google/aarch64-es...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/users/google/received_e...</td>\n",
       "      <td>Organization</td>\n",
       "      <td>public</td>\n",
       "      <td>False</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>Apache License 2.0</td>\n",
       "      <td>Apache-2.0</td>\n",
       "      <td>https://api.github.com/licenses/apache-2.0</td>\n",
       "      <td>MDc6TGljZW5zZTI=</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487987687</td>\n",
       "      <td>R_kgDOHRYZ5w</td>\n",
       "      <td>aarch64-paging</td>\n",
       "      <td>google/aarch64-paging</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/google/aarch64-paging</td>\n",
       "      <td>A Rust library to manipulate AArch64 VMSA EL1 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://api.github.com/repos/google/aarch64-pa...</td>\n",
       "      <td>https://api.github.com/repos/google/aarch64-pa...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.github.com/users/google/received_e...</td>\n",
       "      <td>Organization</td>\n",
       "      <td>public</td>\n",
       "      <td>False</td>\n",
       "      <td>other</td>\n",
       "      <td>Other</td>\n",
       "      <td>NOASSERTION</td>\n",
       "      <td>None</td>\n",
       "      <td>MDc6TGljZW5zZTA=</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                           node_id                 name  \\\n",
       "0  460600860                      R_kgDOG3Q2HA             .allstar   \n",
       "1  170908616  MDEwOlJlcG9zaXRvcnkxNzA5MDg2MTY=              .github   \n",
       "2  143044068  MDEwOlJlcG9zaXRvcnkxNDMwNDQwNjg=      0x0g-2018-badge   \n",
       "3  424674738                      R_kgDOGVAFsg  aarch64-esr-decoder   \n",
       "4  487987687                      R_kgDOHRYZ5w       aarch64-paging   \n",
       "\n",
       "                    full_name  private  \\\n",
       "0             google/.allstar    False   \n",
       "1              google/.github    False   \n",
       "2      google/0x0g-2018-badge    False   \n",
       "3  google/aarch64-esr-decoder    False   \n",
       "4       google/aarch64-paging    False   \n",
       "\n",
       "                                        html_url  \\\n",
       "0             https://github.com/google/.allstar   \n",
       "1              https://github.com/google/.github   \n",
       "2      https://github.com/google/0x0g-2018-badge   \n",
       "3  https://github.com/google/aarch64-esr-decoder   \n",
       "4       https://github.com/google/aarch64-paging   \n",
       "\n",
       "                                         description   fork  \\\n",
       "0                                               None  False   \n",
       "1            default configuration for @google repos  False   \n",
       "2                                               None  False   \n",
       "3  A utility for decoding aarch64 ESR register va...  False   \n",
       "4  A Rust library to manipulate AArch64 VMSA EL1 ...  False   \n",
       "\n",
       "                                                 url  \\\n",
       "0       https://api.github.com/repos/google/.allstar   \n",
       "1        https://api.github.com/repos/google/.github   \n",
       "2  https://api.github.com/repos/google/0x0g-2018-...   \n",
       "3  https://api.github.com/repos/google/aarch64-es...   \n",
       "4  https://api.github.com/repos/google/aarch64-pa...   \n",
       "\n",
       "                                           forks_url  ...  \\\n",
       "0  https://api.github.com/repos/google/.allstar/f...  ...   \n",
       "1  https://api.github.com/repos/google/.github/forks  ...   \n",
       "2  https://api.github.com/repos/google/0x0g-2018-...  ...   \n",
       "3  https://api.github.com/repos/google/aarch64-es...  ...   \n",
       "4  https://api.github.com/repos/google/aarch64-pa...  ...   \n",
       "\n",
       "                           owner.received_events_url    owner.type  \\\n",
       "0  https://api.github.com/users/google/received_e...  Organization   \n",
       "1  https://api.github.com/users/google/received_e...  Organization   \n",
       "2  https://api.github.com/users/google/received_e...  Organization   \n",
       "3  https://api.github.com/users/google/received_e...  Organization   \n",
       "4  https://api.github.com/users/google/received_e...  Organization   \n",
       "\n",
       "  owner.user_view_type owner.site_admin license.key        license.name  \\\n",
       "0               public            False  apache-2.0  Apache License 2.0   \n",
       "1               public            False         NaN                 NaN   \n",
       "2               public            False  apache-2.0  Apache License 2.0   \n",
       "3               public            False  apache-2.0  Apache License 2.0   \n",
       "4               public            False       other               Other   \n",
       "\n",
       "  license.spdx_id                                 license.url  \\\n",
       "0      Apache-2.0  https://api.github.com/licenses/apache-2.0   \n",
       "1             NaN                                         NaN   \n",
       "2      Apache-2.0  https://api.github.com/licenses/apache-2.0   \n",
       "3      Apache-2.0  https://api.github.com/licenses/apache-2.0   \n",
       "4     NOASSERTION                                        None   \n",
       "\n",
       "    license.node_id license  \n",
       "0  MDc6TGljZW5zZTI=     NaN  \n",
       "1               NaN     NaN  \n",
       "2  MDc6TGljZW5zZTI=     NaN  \n",
       "3  MDc6TGljZW5zZTI=     NaN  \n",
       "4  MDc6TGljZW5zZTA=     NaN  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r = pd.json_normalize(\n",
    "    df_repos.to_dict(orient=\"records\")\n",
    ")\n",
    "df_r.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 79 columns):\n",
      " #   Column                       Non-Null Count  Dtype              \n",
      "---  ------                       --------------  -----              \n",
      " 0   id                           30 non-null     int64              \n",
      " 1   node_id                      30 non-null     object             \n",
      " 2   name                         30 non-null     object             \n",
      " 3   full_name                    30 non-null     object             \n",
      " 4   private                      30 non-null     bool               \n",
      " 5   owner                        30 non-null     object             \n",
      " 6   html_url                     30 non-null     object             \n",
      " 7   description                  14 non-null     object             \n",
      " 8   fork                         30 non-null     bool               \n",
      " 9   url                          30 non-null     object             \n",
      " 10  forks_url                    30 non-null     object             \n",
      " 11  keys_url                     30 non-null     object             \n",
      " 12  collaborators_url            30 non-null     object             \n",
      " 13  teams_url                    30 non-null     object             \n",
      " 14  hooks_url                    30 non-null     object             \n",
      " 15  issue_events_url             30 non-null     object             \n",
      " 16  events_url                   30 non-null     object             \n",
      " 17  assignees_url                30 non-null     object             \n",
      " 18  branches_url                 30 non-null     object             \n",
      " 19  tags_url                     30 non-null     object             \n",
      " 20  blobs_url                    30 non-null     object             \n",
      " 21  git_tags_url                 30 non-null     object             \n",
      " 22  git_refs_url                 30 non-null     object             \n",
      " 23  trees_url                    30 non-null     object             \n",
      " 24  statuses_url                 30 non-null     object             \n",
      " 25  languages_url                30 non-null     object             \n",
      " 26  stargazers_url               30 non-null     object             \n",
      " 27  contributors_url             30 non-null     object             \n",
      " 28  subscribers_url              30 non-null     object             \n",
      " 29  subscription_url             30 non-null     object             \n",
      " 30  commits_url                  30 non-null     object             \n",
      " 31  git_commits_url              30 non-null     object             \n",
      " 32  comments_url                 30 non-null     object             \n",
      " 33  issue_comment_url            30 non-null     object             \n",
      " 34  contents_url                 30 non-null     object             \n",
      " 35  compare_url                  30 non-null     object             \n",
      " 36  merges_url                   30 non-null     object             \n",
      " 37  archive_url                  30 non-null     object             \n",
      " 38  downloads_url                30 non-null     object             \n",
      " 39  issues_url                   30 non-null     object             \n",
      " 40  pulls_url                    30 non-null     object             \n",
      " 41  milestones_url               30 non-null     object             \n",
      " 42  notifications_url            30 non-null     object             \n",
      " 43  labels_url                   30 non-null     object             \n",
      " 44  releases_url                 30 non-null     object             \n",
      " 45  deployments_url              30 non-null     object             \n",
      " 46  created_at                   30 non-null     datetime64[ns, UTC]\n",
      " 47  updated_at                   30 non-null     datetime64[ns, UTC]\n",
      " 48  pushed_at                    30 non-null     datetime64[ns, UTC]\n",
      " 49  git_url                      30 non-null     object             \n",
      " 50  ssh_url                      30 non-null     object             \n",
      " 51  clone_url                    30 non-null     object             \n",
      " 52  svn_url                      30 non-null     object             \n",
      " 53  homepage                     14 non-null     object             \n",
      " 54  size                         30 non-null     int64              \n",
      " 55  stargazers_count             30 non-null     int64              \n",
      " 56  watchers_count               30 non-null     int64              \n",
      " 57  language                     27 non-null     object             \n",
      " 58  has_issues                   30 non-null     bool               \n",
      " 59  has_projects                 30 non-null     bool               \n",
      " 60  has_downloads                30 non-null     bool               \n",
      " 61  has_wiki                     30 non-null     bool               \n",
      " 62  has_pages                    30 non-null     bool               \n",
      " 63  has_discussions              30 non-null     bool               \n",
      " 64  forks_count                  30 non-null     int64              \n",
      " 65  mirror_url                   0 non-null      float64            \n",
      " 66  archived                     30 non-null     bool               \n",
      " 67  disabled                     30 non-null     bool               \n",
      " 68  open_issues_count            30 non-null     int64              \n",
      " 69  license                      29 non-null     object             \n",
      " 70  allow_forking                30 non-null     bool               \n",
      " 71  is_template                  30 non-null     bool               \n",
      " 72  web_commit_signoff_required  30 non-null     bool               \n",
      " 73  topics                       30 non-null     object             \n",
      " 74  visibility                   30 non-null     object             \n",
      " 75  forks                        30 non-null     int64              \n",
      " 76  open_issues                  30 non-null     int64              \n",
      " 77  watchers                     30 non-null     int64              \n",
      " 78  default_branch               30 non-null     object             \n",
      "dtypes: bool(13), datetime64[ns, UTC](3), float64(1), int64(9), object(53)\n",
      "memory usage: 16.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_repos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y ahora como le hacemos con la biblioteca de `json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de entradas: 30\n",
      "\n",
      "Nombre de los atributos: id, node_id, name, full_name, private, owner, html_url, description, fork, url, forks_url, keys_url, collaborators_url, teams_url, hooks_url, issue_events_url, events_url, assignees_url, branches_url, tags_url, blobs_url, git_tags_url, git_refs_url, trees_url, statuses_url, languages_url, stargazers_url, contributors_url, subscribers_url, subscription_url, commits_url, git_commits_url, comments_url, issue_comment_url, contents_url, compare_url, merges_url, archive_url, downloads_url, issues_url, pulls_url, milestones_url, notifications_url, labels_url, releases_url, deployments_url, created_at, updated_at, pushed_at, git_url, ssh_url, clone_url, svn_url, homepage, size, stargazers_count, watchers_count, language, has_issues, has_projects, has_downloads, has_wiki, has_pages, has_discussions, forks_count, mirror_url, archived, disabled, open_issues_count, license, allow_forking, is_template, web_commit_signoff_required, topics, visibility, forks, open_issues, watchers, default_branch\n",
      "\n",
      "Atributos de 'owner': login, id, node_id, avatar_url, gravatar_id, url, html_url, followers_url, following_url, gists_url, starred_url, subscriptions_url, organizations_url, repos_url, events_url, received_events_url, type, user_view_type, site_admin\n"
     ]
    }
   ],
   "source": [
    "with open(subdir + archivo_nombre, 'r') as fp:\n",
    "    repos = json.load(fp)\n",
    "\n",
    "print(f\"\\nNúmero de entradas: {len(repos)}\")\n",
    "print(f\"\\nNombre de los atributos: { ', '.join(repos[0].keys())}\")\n",
    "print(f\"\\nAtributos de 'owner': {', '.join(repos[0]['owner'].keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Utiliza los archivos `json` descargados con el detalle a nivel estatal, y genera unos 3 `DataFrame` con información sobre personas desaparecidas dependiendo de diferentes características. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos JSON\n",
    "\n",
    "ruta = \"./data/desaparecidos_nacional.json\"\n",
    "\n",
    "with open(ruta, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict,\n",
       " dict_keys(['totales', 'espacial', 'anual', 'mensual_ultimo_anio', 'por_edad', 'por_nacionalidad']))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora revisamos su estructura:\n",
    "type(data), data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totales.PorcentajeDesaparecidos</th>\n",
       "      <th>totales.PorcentajeLocalizados</th>\n",
       "      <th>totales.PorcentajeLocalizadosCV</th>\n",
       "      <th>totales.PorcentajeLocalizadosSV</th>\n",
       "      <th>totales.PorcentajeSoloDesaparecidos</th>\n",
       "      <th>totales.PorcentajeSoloNoLocalizados</th>\n",
       "      <th>totales.TotalDesaparecidos</th>\n",
       "      <th>totales.TotalGlobal</th>\n",
       "      <th>totales.TotalLocalizados</th>\n",
       "      <th>totales.TotalLocalizadosCV</th>\n",
       "      <th>...</th>\n",
       "      <th>por_nacionalidad.Mujeres.SALVADORENA</th>\n",
       "      <th>por_nacionalidad.Mujeres.SE DESCONOCE</th>\n",
       "      <th>por_nacionalidad.Mujeres.SIN NACIONALIDAD DE REFERENCIA</th>\n",
       "      <th>por_nacionalidad.Mujeres.SLOVAKO</th>\n",
       "      <th>por_nacionalidad.Mujeres.SUECA</th>\n",
       "      <th>por_nacionalidad.Mujeres.SUIZA</th>\n",
       "      <th>por_nacionalidad.Mujeres.TURCA</th>\n",
       "      <th>por_nacionalidad.Mujeres.UKRANIANA</th>\n",
       "      <th>por_nacionalidad.Mujeres.URUGUAYA</th>\n",
       "      <th>por_nacionalidad.Mujeres.VENEZOLANA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.61</td>\n",
       "      <td>59.39</td>\n",
       "      <td>93.39</td>\n",
       "      <td>6.61</td>\n",
       "      <td>90.57</td>\n",
       "      <td>9.43</td>\n",
       "      <td>90223</td>\n",
       "      <td>222181</td>\n",
       "      <td>131958</td>\n",
       "      <td>123230</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>3583</td>\n",
       "      <td>4262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 856 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  totales.PorcentajeDesaparecidos totales.PorcentajeLocalizados  \\\n",
       "0                           40.61                         59.39   \n",
       "\n",
       "  totales.PorcentajeLocalizadosCV totales.PorcentajeLocalizadosSV  \\\n",
       "0                           93.39                            6.61   \n",
       "\n",
       "  totales.PorcentajeSoloDesaparecidos totales.PorcentajeSoloNoLocalizados  \\\n",
       "0                               90.57                                9.43   \n",
       "\n",
       "  totales.TotalDesaparecidos totales.TotalGlobal totales.TotalLocalizados  \\\n",
       "0                      90223              222181                   131958   \n",
       "\n",
       "  totales.TotalLocalizadosCV  ... por_nacionalidad.Mujeres.SALVADORENA  \\\n",
       "0                     123230  ...                                   60   \n",
       "\n",
       "  por_nacionalidad.Mujeres.SE DESCONOCE  \\\n",
       "0                                  3583   \n",
       "\n",
       "  por_nacionalidad.Mujeres.SIN NACIONALIDAD DE REFERENCIA  \\\n",
       "0                                               4262        \n",
       "\n",
       "   por_nacionalidad.Mujeres.SLOVAKO  por_nacionalidad.Mujeres.SUECA  \\\n",
       "0                                 0                               0   \n",
       "\n",
       "   por_nacionalidad.Mujeres.SUIZA  por_nacionalidad.Mujeres.TURCA  \\\n",
       "0                               0                               1   \n",
       "\n",
       "   por_nacionalidad.Mujeres.UKRANIANA  por_nacionalidad.Mujeres.URUGUAYA  \\\n",
       "0                                   2                                  1   \n",
       "\n",
       "   por_nacionalidad.Mujeres.VENEZOLANA  \n",
       "0                                   21  \n",
       "\n",
       "[1 rows x 856 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspeccionar la estructura interna\n",
    "pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totales <class 'dict'>\n",
      "espacial <class 'dict'>\n",
      "anual <class 'dict'>\n",
      "mensual_ultimo_anio <class 'dict'>\n",
      "por_edad <class 'dict'>\n",
      "por_nacionalidad <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for k in data:\n",
    "    print(k, type(data[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGUASCALIENTES', 'BAJA CALIFORNIA', 'BAJA CALIFORNIA SUR', 'CAMPECHE',\n",
       "       'CHIAPAS', 'CHIHUAHUA', 'CIUDAD DE MEXICO', 'COAHUILA', 'COLIMA',\n",
       "       'DURANGO', 'ESTADO DE MEXICO', 'GUANAJUATO', 'GUERRERO', 'HIDALGO',\n",
       "       'JALISCO', 'MICHOACAN ', 'MORELOS', 'NAYARIT', 'NUEVO LEON', 'OAXACA',\n",
       "       'PUEBLA', 'QUERETARO ', 'QUINTANA ROO', 'SAN LUIS POTOSI',\n",
       "       'SE DESCONOCE', 'SINALOA', 'SONORA', 'TABASCO', 'TAMAULIPAS',\n",
       "       'TLAXCALA', 'VERACRUZ ', 'YUCATAN', 'ZACATECAS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estado.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1er Dataframe: DF por ESTADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_estado creado. Shape: (33, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estado</th>\n",
       "      <th>total_desaparecidos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTADO DE MEXICO</td>\n",
       "      <td>39782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JALISCO</td>\n",
       "      <td>20450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TAMAULIPAS</td>\n",
       "      <td>17030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GUANAJUATO</td>\n",
       "      <td>15093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHIHUAHUA</td>\n",
       "      <td>12322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SINALOA</td>\n",
       "      <td>10659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CIUDAD DE MEXICO</td>\n",
       "      <td>10491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PUEBLA</td>\n",
       "      <td>9376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NUEVO LEON</td>\n",
       "      <td>9040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>YUCATAN</td>\n",
       "      <td>6832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VERACRUZ</td>\n",
       "      <td>6812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SONORA</td>\n",
       "      <td>6575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              estado  total_desaparecidos\n",
       "0   ESTADO DE MEXICO                39782\n",
       "1            JALISCO                20450\n",
       "2         TAMAULIPAS                17030\n",
       "3         GUANAJUATO                15093\n",
       "4          CHIHUAHUA                12322\n",
       "5            SINALOA                10659\n",
       "6   CIUDAD DE MEXICO                10491\n",
       "7             PUEBLA                 9376\n",
       "8         NUEVO LEON                 9040\n",
       "9            YUCATAN                 6832\n",
       "10         VERACRUZ                  6812\n",
       "11            SONORA                 6575"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ---------- 1) DATAFRAME POR ESTADO (totales) ----------\n",
    "esp = data.get(\"espacial\", {})\n",
    "\n",
    "def df_por_estado_desde_esp(esp_dict):\n",
    "    \"\"\"\n",
    "    Devuelve un DataFrame con columnas ['estado', 'total_desaparecidos'].\n",
    "    Maneja:\n",
    "      - esp_dict = {estado: numero}\n",
    "      - esp_dict = {estado: {subk: val, ...}}\n",
    "      - esp_dict = {metric: {estado: val, ...}} (transpuesto)\n",
    "    \"\"\"\n",
    "    # Caso A: valores directos (estado -> número)\n",
    "    sample_values = list(esp_dict.values())[:5]\n",
    "    if all(not isinstance(v, dict) for v in sample_values):\n",
    "        rows = [{\"estado\": k, \"total_desaparecidos\": v} for k, v in esp_dict.items()]\n",
    "        df = pd.DataFrame(rows)\n",
    "        df[\"total_desaparecidos\"] = pd.to_numeric(df[\"total_desaparecidos\"], errors=\"coerce\")\n",
    "        return df.sort_values(\"total_desaparecidos\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Caso B o C: los valores son dicts.\n",
    "    # Construimos un DataFrame intermedio orient='index' (cada clave del dict -> fila)\n",
    "    df_mid = pd.DataFrame.from_dict(esp_dict, orient=\"index\")\n",
    "    # Si las columnas parecen ser estados (mayúsculas y nombre largo), significa que está transpuesto:\n",
    "    cols = list(df_mid.columns)\n",
    "    # heurística: si la mayoría de columnas son nombres en mayúscula o contienen espacios (p.e. \"SONORA\", \"JALISCO\")\n",
    "    n_cols = len(cols)\n",
    "    if n_cols > 1 and sum(1 for c in cols if isinstance(c, str) and re.search(r\"[A-ZÁÉÍÓÚÑ]{2,}\", c)) / n_cols > 0.4:\n",
    "        # df_mid: index = métricas, columns = estados --> necesitamos la fila 'total' (o similar)\n",
    "        # Buscamos fila que contenga 'tot' en su nombre (TOTAL, Totales, total, etc.)\n",
    "        candidate_rows = [idx for idx in df_mid.index if re.search(r\"tot\", str(idx), re.I)]\n",
    "        if candidate_rows:\n",
    "            serie_total = df_mid.loc[candidate_rows[0]]\n",
    "        else:\n",
    "            # Si no hay fila 'total', sumamos filas numéricas para obtener totales por estado\n",
    "            serie_total = df_mid.select_dtypes(include=[\"number\"]).sum(axis=0)\n",
    "        df_final = serie_total.reset_index()\n",
    "        df_final.columns = [\"estado\", \"total_desaparecidos\"]\n",
    "        df_final[\"total_desaparecidos\"] = pd.to_numeric(df_final[\"total_desaparecidos\"], errors=\"coerce\")\n",
    "        return df_final.sort_values(\"total_desaparecidos\", ascending=False).reset_index(drop=True)\n",
    "    else:\n",
    "        # Caso B: df_mid index = estados, columns = métricas -> buscamos columna 'total' dentro\n",
    "        # Renombramos índice a 'estado' y seguimos\n",
    "        df_mid = df_mid.reset_index().rename(columns={\"index\": \"estado\"})\n",
    "        # Buscamos la columna más probable que represente totales\n",
    "        candidate_cols = [c for c in df_mid.columns if re.search(r\"tot|cant|total|desaparecid\", str(c), re.I)]\n",
    "        if candidate_cols:\n",
    "            col_total = candidate_cols[0]\n",
    "            df_res = df_mid[[\"estado\", col_total]].rename(columns={col_total: \"total_desaparecidos\"})\n",
    "            df_res[\"total_desaparecidos\"] = pd.to_numeric(df_res[\"total_desaparecidos\"], errors=\"coerce\")\n",
    "            return df_res.sort_values(\"total_desaparecidos\", ascending=False).reset_index(drop=True)\n",
    "        else:\n",
    "            # Si no encontramos columna obvia, intentamos tomar la suma de todas las columnas numéricas por fila\n",
    "            numeric = df_mid.select_dtypes(include=[\"number\"])\n",
    "            if not numeric.empty:\n",
    "                df_mid[\"total_desaparecidos\"] = numeric.sum(axis=1)\n",
    "                df_res = df_mid[[\"index\", \"total_desaparecidos\"]].rename(columns={\"index\": \"estado\"})\n",
    "                return df_res.sort_values(\"total_desaparecidos\", ascending=False).reset_index(drop=True)\n",
    "            else:\n",
    "                # último recurso: convertir todos los valores no-nulos a string y no perder datos\n",
    "                df_mid[\"total_desaparecidos\"] = None\n",
    "                df_res = df_mid[[\"index\", \"total_desaparecidos\"]].rename(columns={\"index\": \"estado\"})\n",
    "                return df_res\n",
    "\n",
    "# Crear df por estado\n",
    "df_estado = df_por_estado_desde_esp(esp)\n",
    "print(\"df_estado creado. Shape:\", df_estado.shape)\n",
    "display(df_estado.head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2do DataFrame: DF por EDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_por_edad creado. Shape: (3, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rango_edad</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hombres</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mujeres</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indeterminado</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rango_edad  total\n",
       "0        Hombres   1387\n",
       "1        Mujeres   1236\n",
       "2  Indeterminado      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- 2) DATAFRAME POR EDAD ----------\n",
    "pe = data.get(\"por_edad\", {})\n",
    "\n",
    "def df_por_clave_simple(mapping, key_name=\"clave\", val_name=\"total\"):\n",
    "    \"\"\"Convierte dict (posiblemente anidado) a DataFrame (clave, total).\"\"\"\n",
    "    if isinstance(mapping, dict):\n",
    "        # si los valores son dicts, tratamos de extraer un número dentro\n",
    "        sample_vals = list(mapping.values())[:5]\n",
    "        if all(not isinstance(v, dict) for v in sample_vals):\n",
    "            df = pd.DataFrame([(k, v) for k, v in mapping.items()], columns=[key_name, val_name])\n",
    "            df[val_name] = pd.to_numeric(df[val_name], errors=\"coerce\")\n",
    "            return df.sort_values(val_name, ascending=False).reset_index(drop=True)\n",
    "        else:\n",
    "            # por si mapping = {rango: {\"total\": n, ...}}\n",
    "            rows = []\n",
    "            for k, v in mapping.items():\n",
    "                if isinstance(v, dict):\n",
    "                    # buscar campo numérico en el dict (total, cantidad, valor)\n",
    "                    cand = None\n",
    "                    for ck in v:\n",
    "                        if re.search(r\"tot|cant|val|número|num\", str(ck), re.I):\n",
    "                            cand = ck\n",
    "                            break\n",
    "                    if cand is None:\n",
    "                        # tomar la primera columna numérica\n",
    "                        num_cols = [ck for ck, cv in v.items() if isinstance(cv, (int, float))]\n",
    "                        cand = num_cols[0] if num_cols else None\n",
    "                    val = v.get(cand) if cand else None\n",
    "                else:\n",
    "                    val = v\n",
    "                rows.append((k, val))\n",
    "            df = pd.DataFrame(rows, columns=[key_name, val_name])\n",
    "            df[val_name] = pd.to_numeric(df[val_name], errors=\"coerce\")\n",
    "            return df.sort_values(val_name, ascending=False).reset_index(drop=True)\n",
    "    else:\n",
    "        # fallback usando json_normalize\n",
    "        df = pd.json_normalize(mapping)\n",
    "        return df\n",
    "\n",
    "df_por_edad = df_por_clave_simple(pe, key_name=\"rango_edad\", val_name=\"total\")\n",
    "print(\"df_por_edad creado. Shape:\", df_por_edad.shape)\n",
    "display(df_por_edad.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3er DataFrame: DF por NACIONALIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nacionalidad</th>\n",
       "      <th>total_desaparecidos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>MEXICANA</td>\n",
       "      <td>199078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SE DESCONOCE</td>\n",
       "      <td>13156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SIN NACIONALIDAD DE REFERENCIA</td>\n",
       "      <td>7608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ESTADOUNIDENSE</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>HONDUREÑA</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GUATEMALTECA</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SALVADORENA</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>COLOMBIANA</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CUBANA</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NICARAGUENSE</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>VENEZOLANA</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CANADIENSE</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ECUATORIANA</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>PERUANA</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HINDU</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      nacionalidad  total_desaparecidos\n",
       "49                        MEXICANA               199078\n",
       "62                    SE DESCONOCE                13156\n",
       "63  SIN NACIONALIDAD DE REFERENCIA                 7608\n",
       "26                  ESTADOUNIDENSE                  826\n",
       "35                       HONDUREÑA                  402\n",
       "31                    GUATEMALTECA                  296\n",
       "61                     SALVADORENA                  162\n",
       "15                      COLOMBIANA                  157\n",
       "19                          CUBANA                   48\n",
       "53                    NICARAGUENSE                   48\n",
       "70                      VENEZOLANA                   41\n",
       "12                      CANADIENSE                   40\n",
       "22                     ECUATORIANA                   34\n",
       "57                         PERUANA                   30\n",
       "33                           HINDU                   26"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renombrar columna index correctamente\n",
    "df_nac = df_nac.rename(columns={\"index\": \"nacionalidad\"})\n",
    "\n",
    "# Quedarnos solo con lo que nos interesa\n",
    "df_nac = df_nac[[\"nacionalidad\", \"total\"]]\n",
    "\n",
    "# Renombrar total\n",
    "df_nac = df_nac.rename(columns={\"total\": \"total_desaparecidos\"})\n",
    "\n",
    "# Ordenar por frecuencia\n",
    "df_nac = df_nac.sort_values(\"total_desaparecidos\", ascending=False)\n",
    "\n",
    "df_nac.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Archivos xml\n",
    "\n",
    "Los archivos *xml* son una manera de compartir información a través de internet o de guardar información con formatos genéricos que sigue siendo muy utilizada hoy en día. En general lidiar con archivos xml es una pesadilla y se necesita explorarlos con calma y revisarlos bien antes de usarlos. \n",
    "\n",
    "La definición del formato y su uso se puede revisar en [este tutorial de la w3schools](https://www.w3schools.com/xml/default.asp). Vamos a ver un ejemplo sencillo basado en la librería [xml.etree.ElementTree](https://docs.python.org/3/library/xml.etree.elementtree.html) que viene de base en python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opción 1:\n",
      "\tname: Belgian Waffles\n",
      "\tprice: $5.95\n",
      "\tdescription: Two of our famous Belgian Waffles with plenty of real maple syrup\n",
      "\tcalories: 650\n",
      "Opción 2:\n",
      "\tname: Strawberry Belgian Waffles\n",
      "\tprice: $7.95\n",
      "\tdescription: Light Belgian waffles covered with strawberries and whipped cream\n",
      "\tcalories: 900\n",
      "Opción 3:\n",
      "\tname: Berry-Berry Belgian Waffles\n",
      "\tprice: $8.95\n",
      "\tdescription: Belgian waffles covered with assorted fresh berries and whipped cream\n",
      "\tcalories: 900\n",
      "Opción 4:\n",
      "\tname: French Toast\n",
      "\tprice: $4.50\n",
      "\tdescription: Thick slices made from our homemade sourdough bread\n",
      "\tcalories: 600\n",
      "Opción 5:\n",
      "\tname: Homestyle Breakfast\n",
      "\tprice: $6.95\n",
      "\tdescription: Two eggs, bacon or sausage, toast, and our ever-popular hash browns\n",
      "\tcalories: 950\n",
      "Los desayunos disponibles son: Belgian Waffles, Strawberry Belgian Waffles, Berry-Berry Belgian Waffles, French Toast, Homestyle Breakfast\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as et \n",
    "\n",
    "archivo_url = \"https://github.com/mcd-unison/ing-caract/raw/main/ejemplos/integracion/ejemplos/ejemplo.xml\"\n",
    "archivo_nombre = \"ejemplito.xml\"\n",
    "subdir = \"./data/\"\n",
    "\n",
    "if not os.path.exists(subdir + archivo_nombre):\n",
    "    if not os.path.exists(subdir):\n",
    "        os.makedirs(subdir)\n",
    "    urllib.request.urlretrieve(archivo_url, subdir + archivo_nombre)\n",
    "\n",
    "\n",
    "desayunos = et.parse(subdir + archivo_nombre)\n",
    "\n",
    "for (i, des) in enumerate(desayunos.getroot()):\n",
    "    print(\"Opción {}:\".format(i+1))\n",
    "    for prop in des:\n",
    "        print(\"\\t{}: {}\".format(prop.tag, prop.text.strip()))\n",
    "\n",
    "# Se puede buscar por etiquetas y subetiquetas\n",
    "\n",
    "print(\"Los desayunos disponibles son: \" + \n",
    "      \", \".join([p.text for p in desayunos.findall(\"food/name\")]))\n",
    "\n",
    "# ¿Como se podría poner esta información en un DataFrame de `pandas`?\n",
    "# Agreguen tanto código como consideren necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Como se podría poner esta información en un DataFrame de `pandas`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo XML tiene una estructura jerárquica donde el nodo raíz contiene múltiples nodos 'food', y cada uno posee etiquetas internas como 'name', 'price', 'description' y 'calories'.\n",
    "\n",
    "Para convertir estos datos en un DataFrame se recorren todos los nodos 'food' y se extrajeron sus propiedades en forma de diccionario. Cada diccionario representa una fila, y posteriormente se usa pd.DataFrame() para transformar la lista de diccionarios en una tabla estructurada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "      <th>calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Belgian Waffles</td>\n",
       "      <td>$5.95</td>\n",
       "      <td>Two of our famous Belgian Waffles with plenty ...</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Strawberry Belgian Waffles</td>\n",
       "      <td>$7.95</td>\n",
       "      <td>Light Belgian waffles covered with strawberrie...</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berry-Berry Belgian Waffles</td>\n",
       "      <td>$8.95</td>\n",
       "      <td>Belgian waffles covered with assorted fresh be...</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French Toast</td>\n",
       "      <td>$4.50</td>\n",
       "      <td>Thick slices made from our homemade sourdough ...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homestyle Breakfast</td>\n",
       "      <td>$6.95</td>\n",
       "      <td>Two eggs, bacon or sausage, toast, and our eve...</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  price  \\\n",
       "0              Belgian Waffles  $5.95   \n",
       "1   Strawberry Belgian Waffles  $7.95   \n",
       "2  Berry-Berry Belgian Waffles  $8.95   \n",
       "3                 French Toast  $4.50   \n",
       "4          Homestyle Breakfast  $6.95   \n",
       "\n",
       "                                         description calories  \n",
       "0  Two of our famous Belgian Waffles with plenty ...      650  \n",
       "1  Light Belgian waffles covered with strawberrie...      900  \n",
       "2  Belgian waffles covered with assorted fresh be...      900  \n",
       "3  Thick slices made from our homemade sourdough ...      600  \n",
       "4  Two eggs, bacon or sausage, toast, and our eve...      950  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = desayunos.getroot()\n",
    "\n",
    "registros = []\n",
    "\n",
    "for food in root:\n",
    "    fila = {}\n",
    "    for prop in food:\n",
    "        fila[prop.tag] = prop.text.strip()\n",
    "    registros.append(fila)\n",
    "\n",
    "df = pd.DataFrame(registros)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descargando páginas de Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia es un buen ejemplo de un lugar donde la información se guarda y se descarga en forma de archivos xml. Por ejemplo, si queremos descargar datos de la wikipedia [con su herramienta de exportación en python](https://www.mediawiki.org/wiki/Manual:Pywikibot) utilizando [las categorias definidas por Wikipedia](https://es.wikipedia.org/wiki/Portal:Portada).\n",
    "\n",
    "Para descargar los datos de wikipedia, vamos a hacer un uso de la [API de Mediawiki](https://es.wikipedia.org/w/api.php). Utilizando el módulo `requests` de python, podemos hacer una consulta a la API y obtener los datos en formato json. Más adelante vamos a hablar más sobre el uso de APIs para obtención de información.\n",
    "\n",
    "Primero definamos dos funciones, una para consultar el listado de entradas particulares de Wikipedia, y otra para descargar la información necesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL de la API de MediaWiki de Wikipedia en español\n",
    "API_URL = \"https://es.wikipedia.org/w/api.php\"\n",
    "\n",
    "# Cabecera para identificar nuestra aplicación (buena práctica)\n",
    "HEADERS = {\n",
    "    'User-Agent': 'WikiXMLPseudoDump/1.0 (julio.waissman@unison.mx)'\n",
    "}\n",
    "\n",
    "def get_page_titles(category_title):\n",
    "    \"\"\"Obtiene la lista de títulos de páginas de una categoría.\"\"\"\n",
    "    titles = []\n",
    "    cmcontinue = None \n",
    "    while True:\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"list\": \"categorymembers\",\n",
    "            \"cmtitle\": category_title,\n",
    "            \"cmlimit\": \"500\",  # El límite máximo por petición\n",
    "            \"cmcontinue\": cmcontinue\n",
    "        }     \n",
    "        response = requests.get(API_URL, params=params, headers=HEADERS)\n",
    "        data = response.json()\n",
    "        \n",
    "        for member in data['query']['categorymembers']:\n",
    "            titles.append(member['title'])           \n",
    "        if 'continue' in data:\n",
    "            cmcontinue = data['continue']['cmcontinue']\n",
    "        else:\n",
    "            break           \n",
    "    return titles\n",
    "\n",
    "def get_page_content_in_xml(page_titles):\n",
    "    \"\"\"Obtiene el contenido de las páginas en formato XML.\"\"\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"xml\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvprop\": \"content\",\n",
    "        \"rvslots\": \"main\",\n",
    "        \"titles\": \"|\".join(page_titles)\n",
    "    }\n",
    "    response = requests.get(API_URL, params=params, headers=HEADERS)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usamos las funciones para obtener una lista de poetas argentinos, cada uno en formato `xml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo la lista de entradas de 'Poetas de Argentina'...\n",
      "Se encontraron 9 entradas.\n",
      "Procesadas entradas 1 a 50 de 9\n"
     ]
    }
   ],
   "source": [
    "categoria = \"Poetas de Argentina\"\n",
    "    \n",
    "print(f\"Obteniendo la lista de entradas de '{categoria}'...\")\n",
    "titles = get_page_titles('Categoría:'+categoria)\n",
    "\n",
    "print(f\"Se encontraron {len(titles)} entradas.\")\n",
    "if not titles:\n",
    "  raise ValueError(\"No se encontraron páginas en la categoría especificada.\")\n",
    "\n",
    "batch_size = 50 # Lote de títulos para la segunda petición (máximo 50)\n",
    "all_xml_data = []\n",
    "\n",
    "for i in range(0, len(titles), batch_size):\n",
    "  batch_titles = titles[i:i + batch_size]\n",
    "  xml_content = get_page_content_in_xml(batch_titles)\n",
    "  all_xml_data.append(xml_content)\n",
    "  print(f\"Procesadas entradas {i + 1} a {i + batch_size} de {len(titles)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora las juntamos en un solo documento xml y lo guardamos como archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo 'poetas_de_argentina.xml' creado exitosamente con la información completa.\n"
     ]
    }
   ],
   "source": [
    "# Combinar todos los XML en un solo archivo\n",
    "root = et.Element(categoria.lower().replace(\" \", \"_\"))\n",
    "for xml_data in all_xml_data:\n",
    "  # El contenido XML de la API tiene un elemento <api> y dentro <query>, que necesitamos para el contenido\n",
    "  api_root = et.fromstring(xml_data)\n",
    "  query_element = api_root.find('query')\n",
    "  if query_element:\n",
    "    # Los elementos <page> son los que contienen la información de cada poeta\n",
    "    for page_element in query_element.findall('pages/page'):\n",
    "      root.append(page_element)\n",
    "tree = et.ElementTree(root)\n",
    "\n",
    "# Guardamos en un archivo con el mismo nombre que la categoría (con .xml)\n",
    "output_filename = categoria.lower().replace(\" \", \"_\") + \".xml\"\n",
    "with open(output_filename, \"wb\") as f:\n",
    "      # Escribe el XML completo al archivo\n",
    "        tree.write(f, encoding='utf-8', xml_declaration=True)\n",
    "        print(f\"\\nArchivo '{output_filename}' creado exitosamente con la información completa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a ver como leer el archivo `xml` y listar el nombre de los poetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mana Muscarsel Isla\n",
      "Mario Dobry\n",
      "Niní Bernardello\n",
      "Usuaria discusión:Soylacarli/Archivo 3\n",
      "Categoría:Poetas LGBT de Argentina\n",
      "Categoría:Poetas de Argentina por provincia\n",
      "Categoría:Poetas de Argentina por sexo\n",
      "Categoría:Poetas de Argentina por siglo\n",
      "Categoría:Recitadores de Argentina\n"
     ]
    }
   ],
   "source": [
    "poetas = et.parse(output_filename)\n",
    "for poeta in poetas.getroot():\n",
    "    print(poeta.attrib['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Entender la estructura del archivo `xml` de poetas, hacer un query de otro tema que consideren interesante y generar un `DataFrame` con la información más importante. No olvides de comentar tu código y explicar la estructura del archivo `xml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendiendo la estructura del XML de poetas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "El elemento raíz es:\n",
    "<poetas_de_argentina>\n",
    "\n",
    "Además, cada poeta es un <page>:\n",
    "<page title=\"Jorge Luis Borges\" pageid=\"...\" ns=\"0\">\n",
    "Aquí, 'title' es el nombre del poeta, 'pageid' es el ID de Wikipedia y 'ns' es el espacio de nombres (0 = artículo normal).\n",
    "\n",
    "Finalmente, \n",
    "<revisions>\n",
    "    <rev> TEXTO COMPLETO DEL ARTÍCULO </rev>\n",
    "</revisions>\n",
    "<rev> contiene todo el texto del artículo en formato Wiki.\n",
    "\n",
    "El XML tiene estructura jerárquica clara:\n",
    "raíz => page (poeta) => revisions => rev (texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuevo Query: categoría Científicos de México\n",
    "Solo hay que cambiar la variable 'categoría' y lo demás se queda igual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obteniendo la lista de entradas de 'Científicos de México'...\n",
      "Se encontraron 85 entradas.\n",
      "Procesadas entradas 1 a 50 de 85\n",
      "Procesadas entradas 51 a 100 de 85\n"
     ]
    }
   ],
   "source": [
    "categoria = \"Científicos de México\"\n",
    "\n",
    "print(f\"Obteniendo la lista de entradas de '{categoria}'...\")\n",
    "titles = get_page_titles('Categoría:'+categoria)\n",
    "\n",
    "print(f\"Se encontraron {len(titles)} entradas.\")\n",
    "if not titles:\n",
    "  raise ValueError(\"No se encontraron páginas en la categoría especificada.\")\n",
    "\n",
    "batch_size = 50 # Lote de títulos para la segunda petición (máximo 50)\n",
    "all_xml_data = []\n",
    "\n",
    "for i in range(0, len(titles), batch_size):\n",
    "  batch_titles = titles[i:i + batch_size]\n",
    "  xml_content = get_page_content_in_xml(batch_titles)\n",
    "  all_xml_data.append(xml_content)\n",
    "  print(f\"Procesadas entradas {i + 1} a {i + batch_size} de {len(titles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo 'científicos_de_méxico.xml' creado exitosamente con la información completa.\n"
     ]
    }
   ],
   "source": [
    "# Combinar todos los XML en un solo archivo\n",
    "root = et.Element(categoria.lower().replace(\" \", \"_\"))\n",
    "for xml_data in all_xml_data:\n",
    "  # El contenido XML de la API tiene un elemento <api> y dentro <query>, que necesitamos para el contenido\n",
    "  api_root = et.fromstring(xml_data)\n",
    "  query_element = api_root.find('query')\n",
    "  if query_element:\n",
    "    # Los elementos <page> son los que contienen la información de cada poeta\n",
    "    for page_element in query_element.findall('pages/page'):\n",
    "      root.append(page_element)\n",
    "tree = et.ElementTree(root)\n",
    "\n",
    "# Guardamos en un archivo con el mismo nombre que la categoría (con .xml)\n",
    "output_filename = categoria.lower().replace(\" \", \"_\") + \".xml\"\n",
    "with open(output_filename, \"wb\") as f:\n",
    "      # Escribe el XML completo al archivo\n",
    "        tree.write(f, encoding='utf-8', xml_declaration=True)\n",
    "        print(f\"\\nArchivo '{output_filename}' creado exitosamente con la información completa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alejandro Hernández Cárdenas\n",
      "Alejandro Madrigal\n",
      "Alexander Balankin\n",
      "Anatolio Hernández\n",
      "Andrés Eloy Martínez\n",
      "Arturo Molina Gutiérrez\n",
      "Arturo Montero\n",
      "Arturo Reyes-Sandoval\n",
      "Carlos Castillo-Chavez\n",
      "Constantino de Tárnava\n",
      "Cándido Bolívar Pieltáin\n",
      "Daniel Lluch Belda\n",
      "Darío Fernández Fierro\n",
      "Edmundo Calva Cuadrilla\n",
      "Emilio Muñoz Sandoval\n",
      "Enrique Calderón Alzati\n",
      "Federico Javier Ortiz Ibarra\n",
      "Fernando J. Rosales Juárez\n",
      "Francisco Javier Estrada Murguía\n",
      "Francisco Montes de Oca\n",
      "Gabriel Merino\n",
      "George Rosenkranz\n",
      "Germán Martínez Hidalgo\n",
      "Guillermo Ulises Ruiz-Esparza\n",
      "Horacio Astudillo de la Vega\n",
      "Héctor García Molina\n",
      "Ismael Cosío Villegas\n",
      "Jacobo Grinberg\n",
      "Jaime González Cano\n",
      "Jesús González Ortega (botánico)\n",
      "Joaquín Dondé Ibarra\n",
      "José Horacio Gómez\n",
      "José Manuel Herrera Olvera\n",
      "José Martín Espinosa de los Monteros\n",
      "José María Cantú Garza\n",
      "José Rubén Morones Ramírez\n",
      "Juan Luis Cifuentes Lemus\n",
      "Leonardo López Luján\n",
      "Leonardo Oliva de Álzaga\n",
      "Manuel Martínez Fernández\n",
      "Mauricio Terrones Maldonado\n",
      "Pavel A. Ritto\n",
      "Pilar Calveiro\n",
      "Rafael Lucio Nájera\n",
      "Ramón Bravo\n",
      "Rodrigo Balam Muñoz Soto\n",
      "Sanjaya Rajaram\n",
      "Santiago Pacheco Cruz\n",
      "Vicente Fernández Rodríguez\n",
      "Vicente Talanquer\n",
      "Joaquín Velázquez de León\n",
      "Juan José Vilatela\n",
      "Pedro Vander Linden\n",
      "Categoría:Agrónomos de México\n",
      "Categoría:Ambientalistas de México\n",
      "Categoría:Ambientólogos de México\n",
      "Categoría:Arqueólogos de México\n",
      "Categoría:Biólogos de México\n",
      "Categoría:Cartógrafos de México\n",
      "Categoría:Científicas de México\n",
      "Categoría:Científicos de México por estado\n",
      "Categoría:Científicos de Yucatán\n",
      "Categoría:Científicos sociales de México\n",
      "Categoría:Climatólogos de México\n",
      "Categoría:Curadores de México\n",
      "Categoría:Ecólogos de México\n",
      "Categoría:Epistemólogos de México\n",
      "Categoría:Estadísticos de México\n",
      "Categoría:Etnógrafos de México\n",
      "Categoría:Físicos de México\n",
      "Categoría:Geógrafos de México\n",
      "Categoría:Geólogos de México\n",
      "Categoría:Informatólogos de México\n",
      "Categoría:Informáticos de México\n",
      "Categoría:Lingüistas de México\n",
      "Categoría:Matemáticos de México\n",
      "Categoría:Médicos de México\n",
      "Categoría:Naturalistas de México\n",
      "Categoría:Neurocientíficos de México\n",
      "Categoría:Politólogos de México\n",
      "Categoría:Psicoanalistas de México\n",
      "Categoría:Psicólogos de México\n",
      "Categoría:Químicos de México\n",
      "Categoría:Topógrafos de México\n",
      "Categoría:Veterinarios de México\n"
     ]
    }
   ],
   "source": [
    "cientificos = et.parse(output_filename)\n",
    "for cientifico in cientificos.getroot():\n",
    "    print(cientifico.attrib['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un DataFrame desde el XML de científicos mexicanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>pageid</th>\n",
       "      <th>longitud_texto</th>\n",
       "      <th>menciona_unam</th>\n",
       "      <th>menciona_ipn</th>\n",
       "      <th>menciona_unison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alejandro Hernández Cárdenas</td>\n",
       "      <td>10434589</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alejandro Madrigal</td>\n",
       "      <td>4923670</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alexander Balankin</td>\n",
       "      <td>1456618</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anatolio Hernández</td>\n",
       "      <td>10066514</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andrés Eloy Martínez</td>\n",
       "      <td>11023409</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         nombre    pageid  longitud_texto  menciona_unam  \\\n",
       "0  Alejandro Hernández Cárdenas  10434589               0          False   \n",
       "1            Alejandro Madrigal   4923670               0          False   \n",
       "2            Alexander Balankin   1456618               0          False   \n",
       "3            Anatolio Hernández  10066514               0          False   \n",
       "4          Andrés Eloy Martínez  11023409               0          False   \n",
       "\n",
       "   menciona_ipn  menciona_unison  \n",
       "0         False            False  \n",
       "1         False            False  \n",
       "2         False            False  \n",
       "3         False            False  \n",
       "4         False            False  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el XML\n",
    "archivo = \"científicos_de_méxico.xml\"   # o poetas_de_argentina.xml\n",
    "tree = et.parse(archivo)\n",
    "root = tree.getroot()\n",
    "\n",
    "registros = []\n",
    "\n",
    "for page in root:\n",
    "    nombre = page.attrib.get(\"title\")\n",
    "    pageid = page.attrib.get(\"pageid\")\n",
    "    \n",
    "    # Extraer texto del artículo\n",
    "    rev = page.find(\"revisions/rev\")\n",
    "    texto = rev.text if (rev is not None and rev.text is not None) else \"\"\n",
    "    \n",
    "    registros.append({\n",
    "        \"nombre\": nombre,\n",
    "        \"pageid\": pageid,\n",
    "        \"longitud_texto\": len(texto),\n",
    "        \"menciona_unam\": \"UNAM\" in texto.upper(),\n",
    "        \"menciona_ipn\": \"IPN\" in texto.upper(),\n",
    "        \"menciona_unison\": \"UNISON\" in texto.upper()\n",
    "    })\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(registros)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Archivos de Excel\n",
    "\n",
    "Los archivos de excel son a veces nuestros mejores amigos, y otras veces nuestras peores pesadillas. Un archivo en excel (o cualquier otra hoja de cálculo) son formatos muy útiles que permiten compartir información técnica con personas sin preparación técnica, lo que lo vuelve una herramienta muy poderosa para comunicar hallazgos a los usuarios.\n",
    "\n",
    "Igualmente, la manipulación de datos a través de hojas de cálculo, sin usarlas correctamente (esto es, programando cualquier modificación) genera normalmente un caos y una fuga de información importante para una posterior toma de desición. \n",
    "\n",
    "Como buena práctica, si se tiene acceso a la fuente primaria de datos y se puede uno evitar el uso de datos procesados en hoja de calculo, siempre es mejor esa alternativa (como científico de datos o analista de datos). Pero eso muchas veces es imposible.\n",
    "\n",
    "Vamos a dejar la importación desde `xlsx` a los cursos de *DataCamp* que lo tratan magistralmente. Es importante que, para que se pueda importar desde python o R, muchas veces es necesario instalar librerías extras."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "266c02d0b88fb79ac68216b08bc6bf334e56f5daeb776843302a4ad1205260c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
